{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337949f1-e8bf-41c0-bf5f-28926c6b7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import scipy.signal\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit, bisect\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from nptdms import TdmsFile\n",
    "import csv\n",
    "from PythonOTtools import callTDMS, flip_molecule, TDMS_reader, gauss, bimodal, fwd_exponential, \\\n",
    "    rev_exponential, covariance_pds, bimodal_fit, bimodal_fit_singlethreshold, find_prelimEvents, \\\n",
    "    find_prelimEvents_singlethreshold, timeFilterEvents, plot_prelimEvents_withfilter, save_events_padded, save_events_ST_padded, \\\n",
    "    plot_prelimEvents_covthreshold_withfilter, find_event_npyfiles, extend_events_combined_covmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907fcf1-4700-429f-83ed-cfd3abe6f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point to the name of the file. Our data is saved as .tdms files containing the bead positions and some metadata\n",
    "file = 'Insert file name here'\n",
    "\n",
    "#flip the molecule if necessary: 1 for flipped (negative-displacement) molecule, 0 for positive molecule\n",
    "#to average multiple molecules, they must all point the same direction; by convention, all molecules should be positive\n",
    "flipped_molecule = 0\n",
    "\n",
    "#create a numpy array with all the information from the metadata etc\n",
    "trace = callTDMS(file)\n",
    "\n",
    "#flip the molecule\n",
    "if flipped_molecule:\n",
    "    trace = flip_molecule(trace)\n",
    "    \n",
    "#plot the bead positions to see how the trace looks\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(trace[12], trace[7])\n",
    "plt.plot(trace[12], trace[8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db2a9d-e2e8-4a2e-9e8d-4e75bea77d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate covariance over a window, 8 ms by default but can be set by changing cov_window\n",
    "#calculating covariance can be computationally heavy, so this function saves the covariance\n",
    "covar_AB = covariance_pds(trace, cov_window=8)\n",
    "#generate a histogram of the covariances and plot it, so the peaks should be visibile\n",
    "cov_hist = np.histogram(covar_AB, bins = 100)\n",
    "plt.plot(cov_hist[1][:-1:], cov_hist[0])\n",
    "plt.show()\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a39b4-2742-45b7-869e-d62012901888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a bimodal fit of the covariance histogram, and save it in the same folder as the covariance\n",
    "#this function is somewhat sensitive to initial guesses, which might need adjustment\n",
    "#a1, m1, and s1 are the guesses for amplitude, mean, and standard deviation of the lower (bound) peak\n",
    "#a2, m2, and s2 are the same but for the higher (unbound) peak\n",
    "peaks = bimodal_fit(trace, covar_AB, a1 = 3000, m1=6, s1=0.2, a2 = 8000, m2=12, s2 = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f0c61-a9ec-4e7e-bf48-9cb74323cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the peaks from the bimodal fit to guess at preliminary events\n",
    "prelimEvents = find_prelimEvents(covar_AB, peaks[0], peaks[1])\n",
    "#filter out any events shorter than the dead time of the instrument (16ms) or closer than 16 ms from any other event\n",
    "timeFilteredEvents = timeFilterEvents(trace, prelimEvents)\n",
    "#plot the time filtered events, and save this trace\n",
    "plot_prelimEvents_withfilter(trace, covar_AB, prelimEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1c913-0aee-42e5-8903-78b3dd1d074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the events as numpy arrays. Event start and ends are found by crossing a covariance threshold;\n",
    "#this function pads the events by the amounts set in front_pad and back_pad (4000 points by default, or 16 ms)\n",
    "save_events_padded(trace, timeFilteredEvents, covar_AB, front_pad = 4000, back_pad = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c372a-0842-4b69-abe4-12efc026be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above cells must be run for each individual trace prior to performing fuller analysis, which follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2631f07-6d09-49d5-8790-4376145269c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all the events related to a single molecule\n",
    "M1 = 'folder containing a molecule data'\n",
    "#this function finds all the files containing the strings 'covmethod_event' and '.npy'\n",
    "#and returns a list that contains each event's file name\n",
    "M1_events = find_event_npyfiles(M1, 'covmethod_event', '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8caa1-05fb-4326-bfb9-a6276e88ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join together multiple molecules\n",
    "Mtot = M1_events + M2_events + M3_events #for any number of molecules, add more M_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa4d2f-86f5-45a1-a377-74500aa5ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the event lifetimes\n",
    "lifetime_list = lifetime_listgen(Mtot, front_pad=4000, back_pad=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e729c-9702-4eea-8711-f08e831844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function finds the start and stop point of events, as determined by covariance threshold\n",
    "#this is saved as its own numpy array when the prelimEvents function is run\n",
    "Mtot_eventtimes = find_event_times(Mtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1c4dfe-5c3e-4453-a329-b5386b4607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates the time from the end of one event until the start of the next, returning a numpy array\n",
    "Mtot_reattach = reattachmentrate(Mtot_eventtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11deb7-747b-4ffa-a4ca-770e982df01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure the step size\n",
    "#this function saves numpy arrays and histograms of the individual steps\n",
    "step_size_dist(Mtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a71091-83dc-4fc4-9e39-e0cbbf4db636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO GENERATE AN ENSEMBLE AVERAGE\n",
    "#extend events to all be the same lifetime\n",
    "#recall that the saved events are padded by 4000 pts (16 ms) by default\n",
    "#this padding is considered in this function, still 4000 pts by default, but must be changed if initial padding is chaged\n",
    "#postbind_exten and preUB_exten are 4 ms by default\n",
    "#these set how many ms from the transition point to do the averaging for event extension\n",
    "fwd_events_tot, rev_events_tot = extend_events_combined_covmethod(Mtot, front_pad = 4000, back_pad = 4000)\n",
    "#this function returns two large numpy arrays, n x m, where n is the number of events and m is the padded length of the longest event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7054a2-eefd-4e64-83ec-199611197b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average all the extended events together and plot\n",
    "#optionally, save it\n",
    "\n",
    "#recall the front and back padding are 4000 pts by default, but can be changed\n",
    "front_pad = 4000\n",
    "back_pad = 4000\n",
    "#frequency of our data collection in Hertz\n",
    "freq = 250000\n",
    "#the window of points that are included in the plot\n",
    "exten_win = 4000\n",
    "#set what the forward and reverse traces are, just the output of extend_events_combined_covmethod (large numpy arrays)\n",
    "fwd_traces = fwd_events_tot\n",
    "rev_traces = rev_events_tot\n",
    "#create unpadded versions of the numpy arrays (ie, just the data between the start and stop of the event)\n",
    "all_events_unpad_fwd = fwd_traces[...,front_pad:-back_pad]\n",
    "all_events_unpad_rev = rev_traces[...,front_pad:-back_pad]\n",
    "\n",
    "time_interval = 1/freq\n",
    "\n",
    "#create a numpy array of time points, necessary for plotting\n",
    "ext_event_time_padded = np.arange(0, len(fwd_traces[0])) * time_interval\n",
    "#time array for the lengthened events, unpadded, necessary for fitting\n",
    "ext_event_time = ext_event_time_padded[front_pad:-back_pad]\n",
    "#generate guesses for the initial values for fitting exponentials\n",
    "initial_params_fwd = [np.nanmean(all_events_unpad_fwd[:,-exten_win::])-np.nanmean(all_events_unpad_fwd[:,:exten_win:]),\\\n",
    "                60, np.nanmean(all_events_unpad_fwd[:,:exten_win:])]\n",
    "initial_params_rev = [np.nanmean(all_events_unpad_rev[:,-exten_win::])-np.nanmean(all_events_unpad_rev[:,:exten_win:]),\\\n",
    "                8, np.nanmean(all_events_unpad_rev[:,:exten_win:])]\n",
    "#fit forward (popt1) and reverse (popt2) exponentials\n",
    "popt1, pcov1 = scipy.optimize.curve_fit(fwd_exponential, \\\n",
    "        xdata = ext_event_time, ydata = np.nanmean(all_events_unpad_fwd, axis = 0), p0 = initial_params_fwd, maxfev=8000)\n",
    "popt2, pcov2 = scipy.optimize.curve_fit(rev_exponential, \\\n",
    "        xdata = ext_event_time, ydata = np.nanmean(all_events_unpad_rev, axis = 0), p0 = initial_params_rev)\n",
    "#generate curves of fits\n",
    "yfit_fwd = fwd_exponential(ext_event_time, *popt1)\n",
    "yfit_rev = rev_exponential(ext_event_time, *popt2)\n",
    "#plot the data and fits\n",
    "plt.plot(ext_event_time_padded, np.nanmean(fwd_traces, axis = 0), color = 'dimgray', label = \"Forward average\")\n",
    "plt.plot(ext_event_time_padded, np.nanmean(rev_traces, axis = 0), color = 'darkgray', label = \"Reverse average\")\n",
    "plt.plot(ext_event_time, yfit_fwd, 'black', label = popt1[1])\n",
    "plt.plot(ext_event_time, yfit_rev, 'black', label = popt2[1], alpha=0.6)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.gcf()\n",
    "#save with the following function\n",
    "#plt.savefig('/Users/bob/Desktop/20230411/EnsembleAverage.svg', format='svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trapcode)",
   "language": "python",
   "name": "trapcode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
